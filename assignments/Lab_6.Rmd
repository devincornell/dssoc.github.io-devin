---
title: "Lab #6: Working with APIs"
author: "Data Science and Society (Sociology 367)"
date: ""
output: html_document
---


In this lab, we will practice working with application programming interfaces (APIs). Edit the Lab #6 markdown file ([link to file](https://github.com/dssoc/dssoc.github.io/raw/master/assignments/Lab_6.Rmd)) for your submission. Remember to change the "author" field above to your name. **Send the markdown file (.Rmd) to your TA via direct message on Slack.** Be sure to do the required reading!

**Required reading:** 

* [Intro to APIs](https://medium.com/@rwilliams_bv/apis-d389aa68104f), by Beck Williams
* [An Illustrated Introduction to APIs](https://medium.com/epfl-extension-school/an-illustrated-introduction-to-apis-10f8000313b9), by Xavier Adam
* [Obtaining and using access tokens for Twitter](https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html)

**Optional reading:** [Intro to Network Analysis with R, by Jesse Sadle](https://www.jessesadler.com/post/network-analysis-with-r/).



### Required Datasets

We will use the following datasets for the exercises.

(1) `senator_data`: [Senator_Profiles.Rdata](https://github.com/dssoc/dssoc.github.io/raw/master/datasets/Senator_Profiles.Rdata) includes information about all senators, including their twitter handles (in the `screen_name` column).


**Load the datasets and libraries:**
```{r}
library(tidyverse)
library(rtweet)
#load('../datasets/Senator_Profiles.Rdata')
```
<br/><br/>


### API Setup

Follow these two steps to set up your program for exercise.

#### 1. Set up your API credentials with Twitter. 
If you don't already have one, you will need to create a new account. Instructions for extracting the api key can be found [here](https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html).

#### 2. Store your credentials.
Copy and paste the text below into a new json file called `api_credentials.json`. From the instructions in Step 1 we can see how to extract the api key, api secret key, access token, and access token secrets - replace the approprate keys for each of these values.

```
{
  "app": "<app name here>",
	"api_key": "<api key here>",
	"api_secret_key": "<api_secret_key here",
	"access_token": "<access token here>",
	"access_token_secret": "<access token secret here>",
	"bearer_token": "<unused>"
}
```

#### 3. Authenticate your application.

After you have the credentials stored into the json file, run this code to authenticate the application. This simply reads the json data and provides them directly to the `create_token` function of the `rtweet` package. Once you complete this step, you should be able to access Twitter data through the API. See the `rtweet` package documentation to see how to access different types of data.

```{r, eval = F}

# this code will read credentials from the JSON file you created.
#install.packages("rjson")
library('rjson')
creds <- fromJSON(file = 'api_credentials.json')

# will allow you to authenticate your application
token <- create_token(
  app = creds$app,
  consumer_key = creds$api_key,
  consumer_secret = creds$api_secret_key,
  access_token = creds$access_token,
  access_secret = creds$access_token_secret)

# this allows you to check the remaining data
lim <- rate_limit()
lim[, 1:4]

```



## Exercises
<br/>

**1. In your own words, describe what an application programming interface is, and what advantage it provides to data scientists/computational social scientists.**

```{r}
# Your answer here
```
<br/>


**3. Use the API to augment `senator_data` with additional data from the Twitter platform. To do this, you will need to request information about each senator (use the `screen_name` column to get their Twitter handles), and then join (see `left_join`) the Twitter data into the existing dataframe (hint: pay attenttion to capitalization). Once you have done that, describe and demonstrate (e.g. in table or graph) some new insight (e.g. a summary statistic or pattern) that you gain from this new data. What more does it tell you about the senators, the accounts they follow, or how they relate to one another?**
```{r}
# Your answer here
```
<br/>


**5. Using the `get_related_artists()` command in the `spotifyR` package, create a function that takes the `spotifyID` column in the `artist_meta` dataset and returns an edge list. The edge list should include two columns: one with the Spotify ids of the Grammy-nominated artists, and one with the Spotify ids of the artists they are related to. Each row should represent a tie between one Grammy nominee, and one related artist.**
```{r}
# Your answer here
```
<br/>

**6. Now, make a network visualization of the edge list created in Exercise 5. You may do this however you'd like. Although not necessary, you may consider reformatting your data so that the network visual contains only nodes for the Grammy nominees (i.e. those Spotify ids in the `artist_meta` dataset), with edges weighted by the number of related artists they share in common. You may also consider adding artist names from the `artist_meta` dataset as node attributes in your visualization. Alternatively, you may like to gather more information from the Spotify API and add it as node or edge information in your visualization (e.g. coloring nodes by primary genre that the artist belongs to). Be creative :)**
```{r}
# Your answer here
```
<br/>


**7. Again using the `spotifyR` package, decide for yourself on some interesting data that can be added to one of the existing Grammy datasets. What new insight (e.g. a summary statistic or pattern) can you gain from this additional data? What more does it tell you about the nominees, the winners, the songs, or how any/all of these entities relate to one another?**
```{r}
# Your answer here
```
<br/>

**8. Identify another API, whether it has an associated R package or not, and describe how you might use the data available from it in a social/data scientific research project.**
```{r}
# Your answer here
```

